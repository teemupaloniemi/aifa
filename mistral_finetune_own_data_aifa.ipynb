{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teemupaloniemi/aifa/blob/main/mistral_finetune_own_data_aifa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this and then restart session."
      ],
      "metadata": {
        "id": "Lcs4S0PsA9GT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FuXIFTFapAMI",
        "outputId": "97a3c123-155f-4210-fc75-b08194eb7972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# You only need to run this once per machine\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install sentencepiece\n",
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add google drive if you have models or training data there."
      ],
      "metadata": {
        "id": "pRgkaRaIEh_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28HG5wyfg5ep",
        "outputId": "45cd89e5-e589-4e8c-a4aa-f91961f54364"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training data. (I made this from the database contents)"
      ],
      "metadata": {
        "id": "JaJG6QSlEoI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s6f4z8EYmcJ6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training samples: \", len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNvq3WVg_8GX",
        "outputId": "7be6b7eb-b29d-4cb9-e133-ec9d0f0e27b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples:  4859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhw8JiOr3m18"
      },
      "source": [
        "### Formatting prompts\n",
        "Then create a `formatting_func` to structure training examples as prompts. (Dont really need this could refactor in \"train_dataset.map(....)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f-fJR0MlQiTD"
      },
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = example['text']\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shz8Xdv-yRgf"
      },
      "source": [
        "### 2. Load Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ-5idQwzvg-"
      },
      "source": [
        "Let's now load Mistral - teknium/OpenHermes-2.5-Mistral-7B - using 4-bit quantization!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "a7f038a52a22473980f0fb67ecfc5a98",
            "6f9a1cd175ad4e769ed259d6709735d4",
            "8fee0362f325430cbe8af581aff3fa93",
            "12da27af56c84ad39871e1103cefdd84",
            "f9141c8532c14792b197f6813bac8060",
            "9a65bd6d99d24b6b8e2b5d93fee2f261",
            "0fcb7b52b80f45ee94ceccaeadf29061",
            "c8bf88d391d149dfa6271cfdc22977d7",
            "a275e8eec19044609193eaf3d4b12da8",
            "62a8c55c50bc45209af63a9fb7b7af27",
            "0ab5882d8cf449339fbc70b8fd9da73f"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "E0Nl5mWL0k2T",
        "outputId": "aeb430ed-7a98-4595-b91a-55831929ef9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7f038a52a22473980f0fb67ecfc5a98"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjNdXolqyRgf"
      },
      "source": [
        "### 3. Tokenization\n",
        "\n",
        "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
        "\n",
        "\n",
        "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "haSUDD9HyRgf",
        "outputId": "0c5e4bc5-0c38-4f05-d5b0-8c3325537e8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_and_tokenize_prompt(prompt):\n",
        "    return tokenizer(formatting_func(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHnKLcq4yRgg"
      },
      "source": [
        "Reformat the prompt and tokenize each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S3iLAwLh3m19"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ewk27p3m19"
      },
      "source": [
        "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BA8M9yfC3m19",
        "outputId": "f76d29d2-efe9-4636-af6f-3135e9b48a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4859\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBk4Qp_vyRgh"
      },
      "source": [
        "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
        "\n",
        "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMlw8h743m19"
      },
      "source": [
        "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "acINaViR3m19"
      },
      "outputs": [],
      "source": [
        "max_length = 256 # This was an appropriate max length for my dataset\n",
        "\n",
        "def generate_and_tokenize_prompt2(prompt):\n",
        "    result = tokenizer(\n",
        "        formatting_func(prompt),\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lTk-aTog3m19"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQL796OayRgh"
      },
      "source": [
        "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OKHhvxK83m19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c983ef38-d72a-4787-cbcb-beabb32f907a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 1, 32001, 2188, 28747, 1824, 349, 272, 6032, 302, 272, 334, 16327, 28733, 28757, 2153, 28733, 28750, 28734, 28750, 28770, 28733, 28777, 3148, 26548, 28735, 28733, 920, 28779, 3284, 2255, 10782, 28804, 32000, 32001, 13892, 28747, 415, 6032, 302, 272, 334, 16327, 28733, 28757, 2153, 28733, 28750, 28734, 28750, 28770, 28733, 28777, 3148, 26548, 28735, 28733, 920, 28779, 3284, 2255, 10782, 349, 298, 3360, 7193, 17939, 438, 16752, 7153, 5789, 2574, 297, 9308, 10542, 297, 3401, 28725, 690, 5532, 21029, 28725, 4655, 858, 504, 2678, 594, 28725, 304, 451, 4177, 293, 4165, 2040, 304, 13151, 27799, 28723, 32000, 32000]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train_dataset[1]['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6LRa2Zm3m19"
      },
      "source": [
        "Now all the samples should be the same length, `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I55Yo3yy3m19",
        "outputId": "38d2ead5-67e8-4ab3-d30c-35d710961f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4859\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_data_lengths(tokenized_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP3R4enP3m19"
      },
      "source": [
        "### How does the base model do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxbl4ACsyRgi"
      },
      "source": [
        "Optionally, you can check how Mistral does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRhfq_Fa3m19"
      },
      "source": [
        "The `eval_prompt` I used was:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "pa6ux9ni3m19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598d0902-ff93-456a-9811-721ecfcf5045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3567\n",
            "================================================================================\n",
            "Question is:\n",
            " What is the primary goal of the HORIZON-CL5-2024-D6-01-05 framework?\n",
            "================================================================================\n",
            "Expected output:\n",
            " The primary goal of the HORIZON-CL5-2024-D6-01-05 framework is to support the transition to large-scale deployment of connected and automated mobility in Europe.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')\n",
        "\n",
        "l = len(train_dataset)\n",
        "r = random.randint(0, l-1)\n",
        "# Tämä ei ole välttämättä paras idea ottaa testiin koulutusaineistosta\n",
        "# mutta toisaalta tavoite muistaa tietokanta joten ei se sinäänsä haittaakaan\n",
        "eval_prompt = train_dataset[r]['text'].split('<|im_end|>')[0].split(\"user:\")[1]\n",
        "answer = train_dataset[r]['text'].split('assistant:')[1].split(\"<|im_end|>\")[0]\n",
        "print(r)\n",
        "print(80*\"=\")\n",
        "print(\"Question is:\")\n",
        "print(eval_prompt)\n",
        "print(80*\"=\")\n",
        "print(\"Expected output:\")\n",
        "print(answer)\n",
        "print(80*\"=\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test original model."
      ],
      "metadata": {
        "id": "eAM2_nyRGUhI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NidIuFXMyRgi",
        "outputId": "29b3b768-8da6-4848-bb89-85665ca7f0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Answer is:\n",
            "user\n",
            " What is the primary goal of the HORIZON-CL5-2024-D6-01-05 framework? assistant\n",
            "The HORIZON-CL5-2024-D6-01-05 framework is not a well-defined term or framework. It seems to be a combination of various terms and acronyms that do not form a coherent concept. It is possible that some information is missing or misinterpreted. Please provide more context or clarify the terms used so that a more accurate response can be given.\n",
            "================================================================================\n",
            "Compare to this (expected output): \n",
            " The primary goal of the HORIZON-CL5-2024-D6-01-05 framework is to support the transition to large-scale deployment of connected and automated mobility in Europe.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Re-init the tokenizer so it doesn't add padding or eos token\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model_input = tokenizer(\"<|im_start|>user\\n\" + eval_prompt + \"<|im_end|><|im_start|>assistant\\n\", return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(80*\"=\")\n",
        "    print(\"Answer is:\")\n",
        "    ans = tokenizer.decode(model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.00)[0], skip_special_tokens=True)\n",
        "    print(ans)\n",
        "    print(80*\"=\")\n",
        "    print(\"Compare to this (expected output): \")\n",
        "    print(answer)\n",
        "    print(80*\"=\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCAWeCzZyRgi"
      },
      "source": [
        "Observe how the model does out of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AapDoyfAyRgi"
      },
      "source": [
        "### 4. Set Up LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp2gMi1ZzGET"
      },
      "source": [
        "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a9EUEDAl0ss3"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gkIcwsSU01EB"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUYEpEK-yRgj"
      },
      "source": [
        "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XshGNsbxyRgj",
        "outputId": "ab89863d-bccf-4441-8d19-239815b5060b",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32002, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6mTLuQJyRgj"
      },
      "source": [
        "Here we define the LoRA config.\n",
        "\n",
        "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
        "\n",
        "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
        "\n",
        "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ybeyl20n3dYH",
        "outputId": "07fb90d4-b31f-4a5a-baa5-745a3dccdb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 85041216 || all params: 3837128768 || trainable%: 2.2162721436196535\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_FHi_VLyRgn"
      },
      "source": [
        "See how the model looks different now, with the LoRA adapters added:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IaYMWak4yRgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14ca1d7-0b1d-4a37-d873-679109d80041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): MistralForCausalLM(\n",
            "      (model): MistralModel(\n",
            "        (embed_tokens): Embedding(32002, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x MistralDecoderLayer(\n",
            "            (self_attn): MistralAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (rotary_emb): MistralRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): MistralMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): MistralRMSNorm()\n",
            "            (post_attention_layernorm): MistralRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): MistralRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=4096, out_features=32002, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=32, out_features=32002, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05H5MIfjyRgc"
      },
      "source": [
        "### Accelerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TEzYBadkyRgd"
      },
      "outputs": [],
      "source": [
        "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
        "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
        "\n",
        "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
        "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yxSbpKQSLY6B"
      },
      "outputs": [],
      "source": [
        "model = accelerator.prepare_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0MOtwf3zdZp"
      },
      "source": [
        "### 5. Run Training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c_L1131GyRgo"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jq0nX33BmfaC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7303a5dd-861f-45e3-b7a7-f0531426fe5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 34:30, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.345800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.627700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.488000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.448600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.411300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.212500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.338900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.409900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.184800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.222200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.314900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.147800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>1.057400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.237700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>1.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.179000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.944400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>1.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>1.300400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.095600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.164500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>1.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>1.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.107300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>1.055500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>1.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>1.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>1.057300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>1.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.958700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>1.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.999300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.113900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.162700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>1.146600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.134700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>1.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>1.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.983000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>1.101600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>1.339300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.055800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>1.130700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>1.260500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>1.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>1.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.065800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>1.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.978800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>1.123300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>1.029700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>1.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>1.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>1.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>1.168200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>1.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>1.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>1.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.997100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>1.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.971900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.969100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.912600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.807700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.795000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=1.1365747779846191, metrics={'train_runtime': 2071.8115, 'train_samples_per_second': 2.413, 'train_steps_per_second': 1.207, 'total_flos': 5.525199638092186e+16, 'train_loss': 1.1365747779846191, 'epoch': 1.03})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"EU-finetune\"\n",
        "base_model_name = \"mistral\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"/content/drive/MyDrive/ma\" + run_name\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=1,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "        max_steps=2500,\n",
        "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
        "        bf16=False,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_steps=25,              # When to start reporting loss\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=500,                # Save checkpoints every 500 steps\n",
        "        do_eval=False,                # Perform evaluation at the end of training\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D57XqcsyRgo"
      },
      "source": [
        "Restart the kernel here!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SKSnF016yRgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53,
          "referenced_widgets": [
            "c74093f17488447f8db70f6c0663942d",
            "c3386e87b2584d4883a6429a7cf2cd41",
            "7919c6195c934d529fb52c078ae8c9fa",
            "04d32ab17b7249c3933f20621de16918",
            "22e4cd824bfe4efcaadbdc7ef9096782",
            "6cfe696c0b23458eb9beffcd7447287e",
            "46e492fb65fd4b6f9d343bf8d4fa85d9",
            "afa1f328dc3040c193ba118ae9aedff3",
            "2cd98b1026d2488eb1b2820ef6f9f802",
            "1ce2f4aff6a3418fa1ec73de6634a58c",
            "f56c6bc82c3747f495b679c97c75ad4e"
          ]
        },
        "outputId": "e5a420b0-66c2-4c0b-bf33-88ac1f399028"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c74093f17488447f8db70f6c0663942d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,  # Mistral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BxOhAiqyRgp"
      },
      "source": [
        "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GwsiqhWuyRgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f34cdc0-e350-4bd3-ec61-621f7b98e005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/mamistral-EU-finetune/checkpoint-2500\")\n",
        "ft_model.save_pretrained(\"/content/drive/MyDrive/mamistral-EU-finetune/final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX39ibolyRgp"
      },
      "source": [
        "and run your inference!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')\n",
        "\n",
        "l = len(train_dataset)\n",
        "r = 3567 # set this same as above in out of the box model testing\n",
        "# Tämä ei ole välttämättä paras idea ottaa testiin koulutusaineistosta\n",
        "# mutta toisaalta tavoite muistaa tietokanta joten ei se sinäänsä haittaakaan\n",
        "question = train_dataset[r]['text'].split('<|im_end|>')[0].split(\"user:\")[1]\n",
        "answer = train_dataset[r]['text'].split('assistant:')[1].split(\"<|im_end|>\")[0]\n",
        "print(r)\n",
        "print(80*\"=\")\n",
        "print(\"Question is:\")\n",
        "print(question)\n",
        "print(80*\"=\")\n",
        "print(\"Expected output:\")\n",
        "print(answer)\n",
        "print(80*\"=\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUAAFWfB-3N7",
        "outputId": "90712b54-b760-4ea1-d46a-4c18e61169d5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3567\n",
            "================================================================================\n",
            "Question is:\n",
            " What is the primary goal of the HORIZON-CL5-2024-D6-01-05 framework?\n",
            "================================================================================\n",
            "Expected output:\n",
            " The primary goal of the HORIZON-CL5-2024-D6-01-05 framework is to support the transition to large-scale deployment of connected and automated mobility in Europe.\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lMkVNEUvyRgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c5d84c-f8f9-434e-8faf-4bc343d61af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Answer is:\n",
            "  The primary goal of the HORIZON-CL5-2024-D6-01-05 framework is to develop and demonstrate innovative solutions for sustainable and smart mobility, focusing on electric vehicles, shared mobility services, and intelligent transport systems.  The framework aims to support the transition towards a more sustainable and low-carbon transport system, while also addressing the challenges related to urbanization, digitalization, and electrification of the transport sector.  It seeks to\n",
            "================================================================================\n",
            "Compare to this (expected output): \n",
            " The primary goal of the HORIZON-CL5-2024-D6-01-05 framework is to support the transition to large-scale deployment of connected and automated mobility in Europe.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = f\"<|im_start|>user: {question}<|im_end|><|im_start|>assistant: \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(80*\"=\")\n",
        "    print(\"Answer is:\")\n",
        "    ans = tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.00)[0], skip_special_tokens=True)\n",
        "    print(ans.split('assistant:')[1])\n",
        "    print(80*\"=\")\n",
        "    print(\"Compare to this (expected output): \")\n",
        "    print(answer)\n",
        "    print(80*\"=\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show a little inprovement in understanding / memory. Better trainingset could lead to more accurate results."
      ],
      "metadata": {
        "id": "JNZh-hh0MgGy"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7f038a52a22473980f0fb67ecfc5a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f9a1cd175ad4e769ed259d6709735d4",
              "IPY_MODEL_8fee0362f325430cbe8af581aff3fa93",
              "IPY_MODEL_12da27af56c84ad39871e1103cefdd84"
            ],
            "layout": "IPY_MODEL_f9141c8532c14792b197f6813bac8060",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6f9a1cd175ad4e769ed259d6709735d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9a65bd6d99d24b6b8e2b5d93fee2f261",
            "placeholder": "​",
            "style": "IPY_MODEL_0fcb7b52b80f45ee94ceccaeadf29061",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8fee0362f325430cbe8af581aff3fa93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c8bf88d391d149dfa6271cfdc22977d7",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a275e8eec19044609193eaf3d4b12da8",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "12da27af56c84ad39871e1103cefdd84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_62a8c55c50bc45209af63a9fb7b7af27",
            "placeholder": "​",
            "style": "IPY_MODEL_0ab5882d8cf449339fbc70b8fd9da73f",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [01:25&lt;00:00, 39.68s/it]"
          }
        },
        "f9141c8532c14792b197f6813bac8060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a65bd6d99d24b6b8e2b5d93fee2f261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcb7b52b80f45ee94ceccaeadf29061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c8bf88d391d149dfa6271cfdc22977d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a275e8eec19044609193eaf3d4b12da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62a8c55c50bc45209af63a9fb7b7af27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab5882d8cf449339fbc70b8fd9da73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c74093f17488447f8db70f6c0663942d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3386e87b2584d4883a6429a7cf2cd41",
              "IPY_MODEL_7919c6195c934d529fb52c078ae8c9fa",
              "IPY_MODEL_04d32ab17b7249c3933f20621de16918"
            ],
            "layout": "IPY_MODEL_22e4cd824bfe4efcaadbdc7ef9096782",
            "tabbable": null,
            "tooltip": null
          }
        },
        "c3386e87b2584d4883a6429a7cf2cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6cfe696c0b23458eb9beffcd7447287e",
            "placeholder": "​",
            "style": "IPY_MODEL_46e492fb65fd4b6f9d343bf8d4fa85d9",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7919c6195c934d529fb52c078ae8c9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_afa1f328dc3040c193ba118ae9aedff3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2cd98b1026d2488eb1b2820ef6f9f802",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "04d32ab17b7249c3933f20621de16918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1ce2f4aff6a3418fa1ec73de6634a58c",
            "placeholder": "​",
            "style": "IPY_MODEL_f56c6bc82c3747f495b679c97c75ad4e",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [01:21&lt;00:00, 37.89s/it]"
          }
        },
        "22e4cd824bfe4efcaadbdc7ef9096782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfe696c0b23458eb9beffcd7447287e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e492fb65fd4b6f9d343bf8d4fa85d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "afa1f328dc3040c193ba118ae9aedff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cd98b1026d2488eb1b2820ef6f9f802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ce2f4aff6a3418fa1ec73de6634a58c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56c6bc82c3747f495b679c97c75ad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}