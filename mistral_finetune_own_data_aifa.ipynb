{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teemupaloniemi/aifa/blob/main/mistral_finetune_own_data_aifa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this and then restart session."
      ],
      "metadata": {
        "id": "Lcs4S0PsA9GT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FuXIFTFapAMI",
        "outputId": "97a3c123-155f-4210-fc75-b08194eb7972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.11.17)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# You only need to run this once per machine\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install sentencepiece\n",
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add google drive if you have models or training data there."
      ],
      "metadata": {
        "id": "pRgkaRaIEh_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28HG5wyfg5ep",
        "outputId": "45cd89e5-e589-4e8c-a4aa-f91961f54364"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the training data. (I made this from the database contents)"
      ],
      "metadata": {
        "id": "JaJG6QSlEoI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "s6f4z8EYmcJ6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training samples: \", len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNvq3WVg_8GX",
        "outputId": "7be6b7eb-b29d-4cb9-e133-ec9d0f0e27b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples:  4859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhw8JiOr3m18"
      },
      "source": [
        "### Formatting prompts\n",
        "Then create a `formatting_func` to structure training examples as prompts. (Dont really need this could refactor in \"train_dataset.map(....)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "f-fJR0MlQiTD"
      },
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = example['text']\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shz8Xdv-yRgf"
      },
      "source": [
        "### 2. Load Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ-5idQwzvg-"
      },
      "source": [
        "Let's now load Mistral - teknium/OpenHermes-2.5-Mistral-7B - using 4-bit quantization!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1cc161ee6ba849e78d7c7a2c6e7d5e04",
            "fb097e0702cb409f85ae7eb95458786a",
            "566b833fea2f4956966feeea4afc389a",
            "0470b8386355471794adc1f4d34c3ca5",
            "872fa9124f504863b4bcc8bc62fa5692",
            "f6a6ea77ac694a4f85104f76e885e914",
            "aee4f720fae444028e58b97c15fd4c88",
            "d9e3c2ac3fbf4062a1325ba58a500e21",
            "5f6d30bdd7fc4e5191ac27fb1cea2c5c",
            "c91765a6477f416f8b00e8d699ab51bd",
            "489f90912b9a4bd5b4c8eb369bc18628"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "E0Nl5mWL0k2T",
        "outputId": "7fa6bca1-6e80-4302-d2d4-439f5cf885e4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cc161ee6ba849e78d7c7a2c6e7d5e04"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjNdXolqyRgf"
      },
      "source": [
        "### 3. Tokenization\n",
        "\n",
        "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
        "\n",
        "\n",
        "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "haSUDD9HyRgf",
        "outputId": "a39dcc99-41ea-4c48-ee51-8afbb6afadaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_and_tokenize_prompt(prompt):\n",
        "    return tokenizer(formatting_func(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHnKLcq4yRgg"
      },
      "source": [
        "Reformat the prompt and tokenize each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "S3iLAwLh3m19"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ewk27p3m19"
      },
      "source": [
        "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "BA8M9yfC3m19",
        "outputId": "6cd59bdd-98ff-4783-f748-fb7686af4383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4859\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBk4Qp_vyRgh"
      },
      "source": [
        "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
        "\n",
        "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMlw8h743m19"
      },
      "source": [
        "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "acINaViR3m19"
      },
      "outputs": [],
      "source": [
        "max_length = 256 # This was an appropriate max length for my dataset\n",
        "\n",
        "def generate_and_tokenize_prompt2(prompt):\n",
        "    result = tokenizer(\n",
        "        formatting_func(prompt),\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lTk-aTog3m19"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQL796OayRgh"
      },
      "source": [
        "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OKHhvxK83m19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c8cbd89-c42c-41ac-e236-14229803c9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 1, 32001, 2188, 28747, 1824, 349, 272, 6032, 302, 272, 334, 16327, 28733, 28757, 2153, 28733, 28750, 28734, 28750, 28770, 28733, 28777, 3148, 26548, 28735, 28733, 920, 28779, 3284, 2255, 10782, 28804, 32000, 32001, 13892, 28747, 415, 6032, 302, 272, 334, 16327, 28733, 28757, 2153, 28733, 28750, 28734, 28750, 28770, 28733, 28777, 3148, 26548, 28735, 28733, 920, 28779, 3284, 2255, 10782, 349, 298, 3360, 7193, 17939, 438, 16752, 7153, 5789, 2574, 297, 9308, 10542, 297, 3401, 28725, 690, 5532, 21029, 28725, 4655, 858, 504, 2678, 594, 28725, 304, 451, 4177, 293, 4165, 2040, 304, 13151, 27799, 28723, 32000, 32000]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train_dataset[1]['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6LRa2Zm3m19"
      },
      "source": [
        "Now all the samples should be the same length, `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "I55Yo3yy3m19",
        "outputId": "9ecc8a3b-ae2b-4a7d-a9f8-6089e8114240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4859\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_data_lengths(tokenized_train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP3R4enP3m19"
      },
      "source": [
        "### How does the base model do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vxbl4ACsyRgi"
      },
      "source": [
        "Optionally, you can check how Mistral does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRhfq_Fa3m19"
      },
      "source": [
        "The `eval_prompt` I used was:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "pa6ux9ni3m19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6236a4-8f62-445a-f1c3-a7176c042156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Question is:\n",
            " What is the expected duration of calls for proposals under Horizon Europe Framework - HORIZON-CL5-2024-D2-02-01?\n",
            "================================================================================\n",
            "Expected output:\n",
            " Expected duration: 36 months after starting projects.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')\n",
        "\n",
        "l = len(train_dataset)\n",
        "r = random.randint(0, l-1)\n",
        "# Tämä ei ole välttämättä paras idea ottaa testiin koulutusaineistosta\n",
        "# mutta toisaalta tavoite muistaa tietokanta joten ei se sinäänsä haittaakaan\n",
        "eval_prompt = train_dataset[r]['text'].split('<|im_end|>')[0].split(\"user:\")[1]\n",
        "answer = train_dataset[r]['text'].split('assistant:')[1].split(\"<|im_end|>\")[0]\n",
        "print(80*\"=\")\n",
        "print(\"Question is:\")\n",
        "print(eval_prompt)\n",
        "print(80*\"=\")\n",
        "print(\"Expected output:\")\n",
        "print(answer)\n",
        "print(80*\"=\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test original model."
      ],
      "metadata": {
        "id": "eAM2_nyRGUhI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "NidIuFXMyRgi",
        "outputId": "7de33fcc-a5a4-48b3-e20e-ad39773b0703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Answer is:\n",
            "user\n",
            " What is the expected duration of calls for proposals under Horizon Europe Framework - HORIZON-CL5-2024-D2-02-01? assistant\n",
            " The expected duration of calls for proposals under Horizon Europe Framework - HORIZON-CL5-2024-D2-02-01 is 48 months. \n",
            "\n",
            " 1. What is the name of the framework being discussed? \n",
            " Horizon Europe Framework \n",
            " 2. What is the expected duration of calls for proposals under this framework? \n",
            " 48 months \n",
            " 3. What is the name of the call\n",
            "================================================================================\n",
            "Compare to this (expected output): \n",
            " Expected duration: 36 months after starting projects.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Re-init the tokenizer so it doesn't add padding or eos token\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model_input = tokenizer(\"<|im_start|>user\\n\" + eval_prompt + \"<|im_end|><|im_start|>assistant\\n\", return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(80*\"=\")\n",
        "    print(\"Answer is:\")\n",
        "    ans = tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.00)[0], skip_special_tokens=True)\n",
        "    print(ans)\n",
        "    print(80*\"=\")\n",
        "    print(\"Compare to this (expected output): \")\n",
        "    print(answer)\n",
        "    print(80*\"=\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCAWeCzZyRgi"
      },
      "source": [
        "Observe how the model does out of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AapDoyfAyRgi"
      },
      "source": [
        "### 4. Set Up LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp2gMi1ZzGET"
      },
      "source": [
        "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a9EUEDAl0ss3"
      },
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gkIcwsSU01EB"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUYEpEK-yRgj"
      },
      "source": [
        "Let's print the model to examine its layers, as we will apply QLoRA to all the linear layers of the model. Those layers are `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`, and `lm_head`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XshGNsbxyRgj",
        "outputId": "ab89863d-bccf-4441-8d19-239815b5060b",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32002, 4096)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6mTLuQJyRgj"
      },
      "source": [
        "Here we define the LoRA config.\n",
        "\n",
        "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
        "\n",
        "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
        "\n",
        "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ybeyl20n3dYH",
        "outputId": "07fb90d4-b31f-4a5a-baa5-745a3dccdb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 85041216 || all params: 3837128768 || trainable%: 2.2162721436196535\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_FHi_VLyRgn"
      },
      "source": [
        "See how the model looks different now, with the LoRA adapters added:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IaYMWak4yRgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14ca1d7-0b1d-4a37-d873-679109d80041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): MistralForCausalLM(\n",
            "      (model): MistralModel(\n",
            "        (embed_tokens): Embedding(32002, 4096)\n",
            "        (layers): ModuleList(\n",
            "          (0-31): 32 x MistralDecoderLayer(\n",
            "            (self_attn): MistralAttention(\n",
            "              (q_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (k_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (v_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (o_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (rotary_emb): MistralRotaryEmbedding()\n",
            "            )\n",
            "            (mlp): MistralMLP(\n",
            "              (gate_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (up_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (down_proj): lora.Linear4bit(\n",
            "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.05, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "              )\n",
            "              (act_fn): SiLU()\n",
            "            )\n",
            "            (input_layernorm): MistralRMSNorm()\n",
            "            (post_attention_layernorm): MistralRMSNorm()\n",
            "          )\n",
            "        )\n",
            "        (norm): MistralRMSNorm()\n",
            "      )\n",
            "      (lm_head): lora.Linear(\n",
            "        (base_layer): Linear(in_features=4096, out_features=32002, bias=False)\n",
            "        (lora_dropout): ModuleDict(\n",
            "          (default): Dropout(p=0.05, inplace=False)\n",
            "        )\n",
            "        (lora_A): ModuleDict(\n",
            "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
            "        )\n",
            "        (lora_B): ModuleDict(\n",
            "          (default): Linear(in_features=32, out_features=32002, bias=False)\n",
            "        )\n",
            "        (lora_embedding_A): ParameterDict()\n",
            "        (lora_embedding_B): ParameterDict()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05H5MIfjyRgc"
      },
      "source": [
        "### Accelerator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TEzYBadkyRgd"
      },
      "outputs": [],
      "source": [
        "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
        "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
        "\n",
        "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
        "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yxSbpKQSLY6B"
      },
      "outputs": [],
      "source": [
        "model = accelerator.prepare_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0MOtwf3zdZp"
      },
      "source": [
        "### 5. Run Training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c_L1131GyRgo"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jq0nX33BmfaC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7303a5dd-861f-45e3-b7a7-f0531426fe5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 34:30, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.345800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.627700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.488000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.448600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.411300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.212500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.338900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.281300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.257700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.409900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.209900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.184800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.041000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.222200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.138200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.240600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.091900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.314900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.147800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>1.057400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.237700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>1.220000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.179000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>0.944400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.164200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>1.085200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.081900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>1.300400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.312400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.095600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.164500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>1.076300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>1.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.107300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>1.055500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.176100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>1.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>1.115400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.160300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>1.057300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.090800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>1.063600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.958700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>0.965700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>1.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.106000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>0.999300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.113900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.162700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>1.146600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.134700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>1.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>1.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.983000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>1.101600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.095000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>1.339300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.055800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>1.130700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.179400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>1.260500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>1.100200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>1.179500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.065800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>1.103300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.978800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>1.123300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.016500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>1.148100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>1.029700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>1.016200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>1.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>1.073300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.035600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>1.168200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>1.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.131100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>0.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>1.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>1.172800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.997100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>1.069600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>0.971900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.058300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>0.969100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.912600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>0.807700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.795000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2500, training_loss=1.1365747779846191, metrics={'train_runtime': 2071.8115, 'train_samples_per_second': 2.413, 'train_steps_per_second': 1.207, 'total_flos': 5.525199638092186e+16, 'train_loss': 1.1365747779846191, 'epoch': 1.03})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"EU-finetune\"\n",
        "base_model_name = \"mistral\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"/content/drive/MyDrive/ma\" + run_name\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=1,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "        max_steps=2500,\n",
        "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
        "        bf16=False,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_steps=25,              # When to start reporting loss\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=500,                # Save checkpoints every 500 steps\n",
        "        do_eval=False,                # Perform evaluation at the end of training\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D57XqcsyRgo"
      },
      "source": [
        "Restart the kernel here!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SKSnF016yRgp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53,
          "referenced_widgets": [
            "a38d67fdc398449cb4622e1ba208b23b",
            "70b24cc17b8749e78aa98bcd5e01a2fe",
            "815508dc0160488a8bfdc477764345ba",
            "6b2395a166374de48e32dc415f48ad4e",
            "a75e200bca104d6b8e0fbe24ca702dab",
            "c0c4e8ddb00e45d29989d431ca660143",
            "3e4de5b00f6f43f3919ce15c3aaec6a1",
            "c4d2ffc9b87c417688fe3d41d2d2d174",
            "305d535f004a43028dfc5eb38d8b6682",
            "d74026dcfa7c4fb3b13d2f0cd7aaddc7",
            "24b9e6860c7b46dfb730718f94c5ac81"
          ]
        },
        "outputId": "67be4f67-5a11-4ee5-b485-7ae14d836a12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a38d67fdc398449cb4622e1ba208b23b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,  # Mistral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BxOhAiqyRgp"
      },
      "source": [
        "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GwsiqhWuyRgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec343f8-2e83-4ac3-b10a-b84e96225408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/mamistral-EU-finetune/checkpoint-2500\")\n",
        "ft_model.save_pretrained(\"/content/drive/MyDrive/mamistral-EU-finetune/final\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX39ibolyRgp"
      },
      "source": [
        "and run your inference!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import random\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/ma/ready.jsonl', split='train')\n",
        "\n",
        "l = len(train_dataset)\n",
        "r = random.randint(0, l-1)\n",
        "# Tämä ei ole välttämättä paras idea ottaa testiin koulutusaineistosta\n",
        "# mutta toisaalta tavoite muistaa tietokanta joten ei se sinäänsä haittaakaan\n",
        "question = train_dataset[r]['text'].split('<|im_end|>')[0].split(\"user:\")[1]\n",
        "answer = train_dataset[r]['text'].split('assistant:')[1].split(\"<|im_end|>\")[0]\n",
        "print(80*\"=\")\n",
        "print(\"Question is:\")\n",
        "print(question)\n",
        "print(80*\"=\")\n",
        "print(\"Expected output:\")\n",
        "print(answer)\n",
        "print(80*\"=\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUAAFWfB-3N7",
        "outputId": "dd6564d9-6fd4-4a12-99be-091858aa71bb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Question is:\n",
            " What is the name of this Just Transition Mechanism?\n",
            "================================================================================\n",
            "Expected output:\n",
            " JTM-2022-2025-PSLF-STANDALONE-PROJECTS\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lMkVNEUvyRgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0606755-13af-418c-c558-4c004ea8bc48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:32000 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Answer is:\n",
            "  The main goal of MSCA COFUND is to support the implementation of national and regional coordination and support actions for the MSCA.  These actions aim to enhance the attractiveness of the MSCA and to increase the number of researchers participating in the programme.  They also aim to improve the quality of the MSCA by providing better support for researchers and organisations.  The actions should also contribute to the development of a European Research Area (ERA) by promoting cooperation between\n",
            "================================================================================\n",
            "Compare to this (expected output): \n",
            " The main goal of MSCA COFUND is to spread best practices of the MSCA including international, inter-sectoral and interdisciplinary research training, as well as international and cross-sectoral mobility of researchers at all stages of their career. \n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = f\"<|im_start|>user: {question}<|im_end|><|im_start|>assistant: \"\n",
        "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(80*\"=\")\n",
        "    print(\"Answer is:\")\n",
        "    ans = tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.00)[0], skip_special_tokens=True)\n",
        "    print(ans.split('assistant:')[1])\n",
        "    print(80*\"=\")\n",
        "    print(\"Compare to this (expected output): \")\n",
        "    print(answer)\n",
        "    print(80*\"=\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1cc161ee6ba849e78d7c7a2c6e7d5e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb097e0702cb409f85ae7eb95458786a",
              "IPY_MODEL_566b833fea2f4956966feeea4afc389a",
              "IPY_MODEL_0470b8386355471794adc1f4d34c3ca5"
            ],
            "layout": "IPY_MODEL_872fa9124f504863b4bcc8bc62fa5692",
            "tabbable": null,
            "tooltip": null
          }
        },
        "fb097e0702cb409f85ae7eb95458786a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f6a6ea77ac694a4f85104f76e885e914",
            "placeholder": "​",
            "style": "IPY_MODEL_aee4f720fae444028e58b97c15fd4c88",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "566b833fea2f4956966feeea4afc389a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d9e3c2ac3fbf4062a1325ba58a500e21",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f6d30bdd7fc4e5191ac27fb1cea2c5c",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "0470b8386355471794adc1f4d34c3ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c91765a6477f416f8b00e8d699ab51bd",
            "placeholder": "​",
            "style": "IPY_MODEL_489f90912b9a4bd5b4c8eb369bc18628",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [01:20&lt;00:00, 37.60s/it]"
          }
        },
        "872fa9124f504863b4bcc8bc62fa5692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a6ea77ac694a4f85104f76e885e914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aee4f720fae444028e58b97c15fd4c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d9e3c2ac3fbf4062a1325ba58a500e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6d30bdd7fc4e5191ac27fb1cea2c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c91765a6477f416f8b00e8d699ab51bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489f90912b9a4bd5b4c8eb369bc18628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a38d67fdc398449cb4622e1ba208b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70b24cc17b8749e78aa98bcd5e01a2fe",
              "IPY_MODEL_815508dc0160488a8bfdc477764345ba",
              "IPY_MODEL_6b2395a166374de48e32dc415f48ad4e"
            ],
            "layout": "IPY_MODEL_a75e200bca104d6b8e0fbe24ca702dab",
            "tabbable": null,
            "tooltip": null
          }
        },
        "70b24cc17b8749e78aa98bcd5e01a2fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c0c4e8ddb00e45d29989d431ca660143",
            "placeholder": "​",
            "style": "IPY_MODEL_3e4de5b00f6f43f3919ce15c3aaec6a1",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "815508dc0160488a8bfdc477764345ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c4d2ffc9b87c417688fe3d41d2d2d174",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_305d535f004a43028dfc5eb38d8b6682",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "6b2395a166374de48e32dc415f48ad4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d74026dcfa7c4fb3b13d2f0cd7aaddc7",
            "placeholder": "​",
            "style": "IPY_MODEL_24b9e6860c7b46dfb730718f94c5ac81",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [01:20&lt;00:00, 37.41s/it]"
          }
        },
        "a75e200bca104d6b8e0fbe24ca702dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c4e8ddb00e45d29989d431ca660143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e4de5b00f6f43f3919ce15c3aaec6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c4d2ffc9b87c417688fe3d41d2d2d174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305d535f004a43028dfc5eb38d8b6682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d74026dcfa7c4fb3b13d2f0cd7aaddc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24b9e6860c7b46dfb730718f94c5ac81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}